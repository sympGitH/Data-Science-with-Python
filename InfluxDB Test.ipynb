{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InfluxDB Python Client\n",
    "* 메뉴얼 : http://influxdb-python.readthedocs.io/en/latest/\n",
    "* 클라이언트 다운로드 : https://github.com/influxdata/influxdb-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from influxdb import InfluxDBClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = InfluxDBClient('localhost', 8086, 'root', 'root', 'telegraf')\n",
    "# client.create_database('example2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json_body = [\n",
    "    {\n",
    "        \"measurement\": \"scom\",\n",
    "        \"tags\": {\n",
    "            \"host\": \"server01\",\n",
    "            \"region\": \"us-west\"\n",
    "        },\n",
    "        \"time\": \"2016-11-28T10:00:00Z\",\n",
    "        \"fields\": {\n",
    "            \"fatal\": 1,\n",
    "            \"critical\" : 3,\n",
    "            \"normal\" : 7,\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.write_points(json_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create pandas DataFrame\n",
      "Write DataFrame\n",
      "Write DataFrame with Tags\n",
      "Read DataFrame\n",
      "                            0\n",
      "2016-08-29 00:00:00+00:00   0\n",
      "2016-08-29 01:00:00+00:00   1\n",
      "2016-08-29 02:00:00+00:00   2\n",
      "2016-08-29 03:00:00+00:00   3\n",
      "2016-08-29 04:00:00+00:00   4\n",
      "2016-08-29 05:00:00+00:00   5\n",
      "2016-08-29 06:00:00+00:00   6\n",
      "2016-08-29 07:00:00+00:00   7\n",
      "2016-08-29 08:00:00+00:00   8\n",
      "2016-08-29 09:00:00+00:00   9\n",
      "2016-08-29 10:00:00+00:00  10\n",
      "2016-08-29 11:00:00+00:00  11\n",
      "2016-08-29 12:00:00+00:00  12\n",
      "2016-08-29 13:00:00+00:00  13\n",
      "2016-08-29 14:00:00+00:00  14\n",
      "2016-08-29 15:00:00+00:00  15\n",
      "2016-08-29 16:00:00+00:00  16\n",
      "2016-08-29 17:00:00+00:00  17\n",
      "2016-08-29 18:00:00+00:00  18\n",
      "2016-08-29 19:00:00+00:00  19\n",
      "2016-08-29 20:00:00+00:00  20\n",
      "2016-08-29 21:00:00+00:00  21\n",
      "2016-08-29 22:00:00+00:00  22\n",
      "2016-08-29 23:00:00+00:00  23\n",
      "2016-08-30 00:00:00+00:00  24\n",
      "2016-08-30 01:00:00+00:00  25\n",
      "2016-08-30 02:00:00+00:00  26\n",
      "2016-08-30 03:00:00+00:00  27\n",
      "2016-08-30 04:00:00+00:00  28\n",
      "2016-08-30 05:00:00+00:00  29\n",
      "...                        ..\n",
      "2016-08-31 22:00:00+00:00  70\n",
      "2016-08-31 23:00:00+00:00  71\n",
      "2016-09-01 00:00:00+00:00  72\n",
      "2016-09-01 01:00:00+00:00  73\n",
      "2016-09-01 02:00:00+00:00  74\n",
      "2016-09-01 03:00:00+00:00  75\n",
      "2016-09-01 04:00:00+00:00  76\n",
      "2016-09-01 05:00:00+00:00  77\n",
      "2016-09-01 06:00:00+00:00  78\n",
      "2016-09-01 07:00:00+00:00  79\n",
      "2016-09-01 08:00:00+00:00  80\n",
      "2016-09-01 09:00:00+00:00  81\n",
      "2016-09-01 10:00:00+00:00  82\n",
      "2016-09-01 11:00:00+00:00  83\n",
      "2016-09-01 12:00:00+00:00  84\n",
      "2016-09-01 13:00:00+00:00  85\n",
      "2016-09-01 14:00:00+00:00  86\n",
      "2016-09-01 15:00:00+00:00  87\n",
      "2016-09-01 16:00:00+00:00  88\n",
      "2016-09-01 17:00:00+00:00  89\n",
      "2016-09-01 18:00:00+00:00  90\n",
      "2016-09-01 19:00:00+00:00  91\n",
      "2016-09-01 20:00:00+00:00  92\n",
      "2016-09-01 21:00:00+00:00  93\n",
      "2016-09-01 22:00:00+00:00  94\n",
      "2016-09-01 23:00:00+00:00  95\n",
      "2016-09-02 00:00:00+00:00  96\n",
      "2016-09-02 01:00:00+00:00  97\n",
      "2016-09-02 02:00:00+00:00  98\n",
      "2016-09-02 03:00:00+00:00  99\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "from influxdb import DataFrameClient\n",
    "\n",
    "\n",
    "def pandas_test(host='localhost', port=8086):\n",
    "    user = 'root'\n",
    "    password = 'root'\n",
    "    dbname = 'example'\n",
    "\n",
    "    client = DataFrameClient(host, port, user, password, dbname)\n",
    "\n",
    "    print(\"Create pandas DataFrame\")\n",
    "    df = pd.DataFrame(data=list(range(100)),\n",
    "                      index=pd.date_range(start='2016-08-29',\n",
    "                                          periods=100, freq='H'))\n",
    "\n",
    "    print(\"Write DataFrame\")\n",
    "    client.write_points(df, 'demo')\n",
    "\n",
    "    print(\"Write DataFrame with Tags\")\n",
    "    client.write_points(df, 'demo', {'k1': 'v1', 'k2': 'v2'})\n",
    "\n",
    "    print(\"Read DataFrame\")\n",
    "    client.query(\"select * from demo\")\n",
    "    \n",
    "    print(df)\n",
    "\n",
    "    \n",
    "pandas_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "client.create_user('koon', 'koon', admin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client.create_user('telegraf', 'telegraf', admin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': '_internal'},\n",
       " {'name': 'mydb'},\n",
       " {'name': 'example'},\n",
       " {'name': 'example2'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_list_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'admin': True, 'user': 'koon'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_list_users()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResultSet({'('cpu_load_short', None)': [{'host': 'server01', 'value': 0.64, 'region': 'us-west', 'time': '2009-11-10T23:00:00Z'}]})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query('select * from cpu_load_short', database='example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'InfluxDBClient' object has no attribute 'change_database'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-882f1e64bc57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchange_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'example2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'InfluxDBClient' object has no attribute 'change_database'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from influxdb import InfluxDBClient\n",
    "\n",
    "class InfluxDB :\n",
    "    m_conn = None\n",
    "    def __init__(self) :\n",
    "        pass\n",
    "\n",
    "    def open(self) :\n",
    "        bConti = True\n",
    "        while bConti :\n",
    "            try :\n",
    "                self.m_dConn = InfluxDBClient('localhost', 8086, 'koon', 'koon', 'mydb')\n",
    "                bConti = False\n",
    "            except Exception:\n",
    "                time.sleep(CmpGlobal.g_nConnectionRetryInterval)\n",
    "                print(\"--------------------------------- influxdb connect fail -------------------------------------\")\n",
    "                \n",
    "    def insertData(self, jsondata) :\n",
    "        print(\"Write points: {0}\".format(jsondata))\n",
    "        self.m_dConn.write_points(jsondata)\n",
    "\n",
    "class InfluxDBManager :\n",
    "    m_oDBConn = None\n",
    "    \n",
    "    def __init__(self) :\n",
    "        self.m_oDBConn = InfluxDB()\n",
    "        self.m_oDBConn.open()\n",
    "\n",
    "    def insert(self, nNodeId, watt, apc, pfc, pfcval, ipeak, vpeak) :\n",
    "        json_meter_body = [\n",
    "            {\n",
    "                \"measurement\": \"officepower\",\n",
    "                \"tags\": {\n",
    "                    \"node\":  nNodeId\n",
    "                },\n",
    "                \"fields\": {\n",
    "                    \"watt\":  watt,\n",
    "                    \"apc\":  apc,\n",
    "                    \"pfc\":  pfc,\n",
    "                    \"pfcval\": pfcval,\n",
    "                    \"ipeak\" : ipeak,\n",
    "                    \"vpeak\" : vpeak\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        self.m_oDBConn.insertData(json_meter_body)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g_influxdbconn = InfluxDBManager()\n",
    "\n",
    "# 아래와 같이 입력함.\n",
    "#  g_influxdbconn.insert(nNodeId,wattVal,dWattFactor,dPowerFactor,pftVal,iPeak,vPeak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write points: [{'tags': {'node': 'Host01'}, 'measurement': 'officepower', 'fields': {'pfcval': 1, 'watt': 300, 'ipeak': 30, 'pfc': 10, 'vpeak': 20, 'apc': 20}}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_influxdbconn.insert('Host01', 300, 20, 10, 1, 30, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataframeClient with Pandas 예제\n",
    "* https://github.com/influxdata/influxdb-python/tree/master/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create pandas DataFrame\n",
      "Create database: example3\n",
      "Write DataFrame\n",
      "Write DataFrame with Tags\n",
      "Read DataFrame\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "from influxdb import DataFrameClient\n",
    "\n",
    "\n",
    "def main(host='localhost', port=8086):\n",
    "    user = 'root'\n",
    "    password = 'root'\n",
    "    dbname = 'example3'\n",
    "\n",
    "    client = DataFrameClient(host, port, user, password, dbname)\n",
    "\n",
    "    print(\"Create pandas DataFrame\")\n",
    "    df = pd.DataFrame(data=list(range(30)),\n",
    "                      index=pd.date_range(start='2014-11-16',\n",
    "                                          periods=30, freq='H'))\n",
    "\n",
    "    print(\"Create database: \" + dbname)\n",
    "    client.create_database(dbname)\n",
    "\n",
    "    print(\"Write DataFrame\")\n",
    "    client.write_points(df, 'demo')\n",
    "\n",
    "    print(\"Write DataFrame with Tags\")\n",
    "    client.write_points(df, 'demo', {'k1': 'v1', 'k2': 'v2'})\n",
    "\n",
    "    print(\"Read DataFrame\")\n",
    "    client.query(\"select * from demo\")\n",
    "\n",
    "    #print(\"Delete database: \" + dbname)\n",
    "    #client.drop_database(dbname)\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='example code to play with InfluxDB')\n",
    "    parser.add_argument('--host', type=str, required=False,\n",
    "                        default='localhost',\n",
    "                        help='hostname of InfluxDB http API')\n",
    "    parser.add_argument('--port', type=int, required=False, default=8086,\n",
    "                        help='port of InfluxDB http API')\n",
    "    return parser.parse_args()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    #args = parse_args()\n",
    "    #main(host=args.host, port=args.port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InfluxDB Series Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Tutorial/Example how to use the class helper `SeriesHelper`\n",
    "\"\"\"\n",
    "\n",
    "from influxdb import InfluxDBClient\n",
    "from influxdb import SeriesHelper\n",
    "\n",
    "# InfluxDB connections settings\n",
    "host = 'localhost'\n",
    "port = 8086\n",
    "user = 'root'\n",
    "password = 'root'\n",
    "dbname = 'test'\n",
    "\n",
    "myclient = InfluxDBClient(host, port, user, password, dbname)\n",
    "\n",
    "# Uncomment the following code if the database is not yet created\n",
    "# myclient.create_database(dbname)\n",
    "# myclient.create_retention_policy('awesome_policy', '3d', 3, default=True)\n",
    "\n",
    "\n",
    "class MySeriesHelper(SeriesHelper):\n",
    "    # Meta class stores time series helper configuration.\n",
    "    class Meta:\n",
    "        # The client should be an instance of InfluxDBClient.\n",
    "        client = myclient\n",
    "        # The series name must be a string. Add dependent fields/tags in curly brackets.\n",
    "        server_name = 'events.stats.{server_name}'\n",
    "        # Defines all the fields in this time series.\n",
    "        fields = ['some_stat', 'other_stat']\n",
    "        # Defines all the tags for the series.\n",
    "        tags = ['server_name']\n",
    "        # Defines the number of data points to store prior to writing on the wire.\n",
    "        bulk_size = 5\n",
    "        # autocommit must be set to True when using bulk_size\n",
    "        autocommit = True\n",
    "\n",
    "\n",
    "# The following will create *five* (immutable) data points.\n",
    "# Since bulk_size is set to 5, upon the fifth construction call, *all* data\n",
    "# points will be written on the wire via MySeriesHelper.Meta.client.\n",
    "MySeriesHelper(server_name='us.east-1', some_stat=159, other_stat=10)\n",
    "MySeriesHelper(server_name='us.east-1', some_stat=158, other_stat=20)\n",
    "MySeriesHelper(server_name='us.east-1', some_stat=157, other_stat=30)\n",
    "MySeriesHelper(server_name='us.east-1', some_stat=156, other_stat=40)\n",
    "MySeriesHelper(server_name='us.east-1', some_stat=155, other_stat=50)\n",
    "\n",
    "# To manually submit data points which are not yet written, call commit:\n",
    "MySeriesHelper.commit()\n",
    "\n",
    "# To inspect the JSON which will be written, call _json_body_():\n",
    "MySeriesHelper._json_body_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TextFileReader' object has no attribute 'iterrows'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cdb5d8921afd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m#perf_df['host']=perf_df['host'].str.replace('.corp.doosan.com', '',case=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mperf_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         MySeriesHelper(series_name=row['perf_1'], host=row['host'].str.replace('.corp.doosan.com', '',case=False), \n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TextFileReader' object has no attribute 'iterrows'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from os.path import join\n",
    "from influxdb import InfluxDBClient\n",
    "from influxdb import SeriesHelper\n",
    "\n",
    "host = 'localhost'\n",
    "port = 8086\n",
    "user = 'root'\n",
    "password = 'root'\n",
    "dbname = 'test'\n",
    "\n",
    "myclient = InfluxDBClient(host, port, user, password, dbname)\n",
    "\n",
    "class MySeriesHelper(SeriesHelper):\n",
    "    # Meta class stores time series helper configuration.\n",
    "    class Meta:\n",
    "        # The client should be an instance of InfluxDBClient.\n",
    "        client = myclient\n",
    "        # The series name must be a string. Add dependent fields/tags in curly brackets.\n",
    "        series_name = '{series_name}'\n",
    "        \n",
    "        # Defines all the fields in this time series.\n",
    "        fields = ['perf_2', 'perf_3', 'values']\n",
    "        \n",
    "        # Time Value\n",
    "        time = ['time']\n",
    "        \n",
    "        # Defines all the tags for the series.\n",
    "        tags = ['series_name','host']\n",
    "        # Defines the number of data points to store prior to writing on the wire.\n",
    "        bulk_size = 1000\n",
    "        # autocommit must be set to True when using bulk_size\n",
    "        autocommit = True\n",
    "        \n",
    "path='/Volumes/NIFTY/Bigdata/'\n",
    "\n",
    "#날짜 컬럼 파싱\n",
    "#dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "#df = pd.read_csv(infile, parse_dates=['datetime'], date_parser=dateparse)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "perf_df = pd.read_csv(join(path, 'SCOM_Perf_20160921_20161022.txt'), \n",
    "                      sep=\"EhdroAjd@#\", names=['host', 'perf_1', 'perf_2', 'perf_3', 'values', 'regdt'], \n",
    "                      chunksize=10000, #nrows=100000, \n",
    "                      parse_dates=[5], na_values='N/A', engine='python')\n",
    "\n",
    "#perf_df[:10]\n",
    "#perf_df.info()\n",
    "\n",
    "#perf_df['host']=perf_df['host'].str.replace('.corp.doosan.com', '',case=False)\n",
    "\n",
    "for index, row in perf_df.iterrows():\n",
    "    try:\n",
    "        MySeriesHelper(series_name=row['perf_1'], host=row['host'].str.replace('.corp.doosan.com', '',case=False), \n",
    "                       perf_2=row['perf_2'], perf_3=row['perf_3'], \n",
    "                       values=row['values'], time=row['regdt'])\n",
    "\n",
    "        MySeriesHelper.commit()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000\n",
      "1000000\n",
      "1500000\n",
      "2000000\n",
      "2500000\n",
      "3000000\n",
      "3500000\n",
      "4000000\n",
      "4500000\n",
      "5000000\n",
      "5500000\n",
      "6000000\n",
      "6500000\n",
      "7000000\n",
      "7500000\n",
      "8000000\n",
      "8500000\n",
      "9000000\n",
      "9500000\n",
      "10000000\n",
      "10500000\n",
      "11000000\n",
      "11500000\n",
      "12000000\n",
      "12500000\n",
      "13000000\n",
      "13500000\n",
      "14000000\n",
      "14500000\n",
      "15000000\n",
      "15500000\n",
      "16000000\n",
      "16500000\n",
      "17000000\n",
      "17500000\n",
      "18000000\n",
      "18500000\n",
      "19000000\n",
      "19500000\n",
      "20000000\n",
      "20500000\n",
      "21000000\n",
      "21500000\n",
      "22000000\n",
      "22500000\n",
      "23000000\n",
      "23500000\n",
      "24000000\n",
      "24500000\n",
      "25000000\n",
      "25500000\n",
      "26000000\n",
      "26500000\n",
      "27000000\n",
      "27500000\n",
      "28000000\n",
      "28500000\n",
      "29000000\n",
      "29500000\n",
      "30000000\n",
      "30500000\n",
      "31000000\n",
      "31500000\n",
      "32000000\n",
      "32500000\n",
      "33000000\n",
      "33500000\n",
      "34000000\n",
      "34500000\n",
      "35000000\n",
      "35500000\n",
      "36000000\n",
      "36500000\n",
      "37000000\n",
      "37500000\n",
      "38000000\n",
      "38500000\n",
      "39000000\n",
      "39500000\n",
      "40000000\n",
      "40500000\n",
      "41000000\n",
      "41500000\n",
      "42000000\n",
      "42500000\n",
      "43000000\n",
      "43500000\n",
      "44000000\n",
      "44500000\n",
      "45000000\n",
      "45500000\n",
      "46000000\n",
      "46500000\n",
      "47000000\n",
      "47500000\n",
      "48000000\n",
      "48500000\n",
      "49000000\n",
      "49500000\n",
      "50000000\n",
      "50500000\n",
      "51000000\n",
      "51500000\n",
      "52000000\n",
      "52500000\n",
      "53000000\n",
      "53500000\n",
      "54000000\n",
      "54500000\n",
      "55000000\n",
      "55500000\n",
      "56000000\n",
      "56500000\n",
      "57000000\n",
      "57500000\n",
      "58000000\n",
      "58500000\n",
      "59000000\n",
      "59500000\n",
      "60000000\n",
      "60500000\n",
      "61000000\n",
      "61500000\n",
      "62000000\n",
      "62500000\n",
      "63000000\n",
      "63500000\n",
      "64000000\n",
      "64500000\n",
      "65000000\n",
      "65500000\n",
      "66000000\n",
      "66500000\n",
      "67000000\n",
      "67500000\n",
      "68000000\n",
      "68500000\n",
      "69000000\n",
      "69500000\n",
      "70000000\n",
      "70500000\n",
      "71000000\n",
      "71500000\n",
      "72000000\n",
      "72500000\n",
      "73000000\n",
      "73500000\n",
      "74000000\n",
      "74500000\n",
      "75000000\n",
      "75500000\n",
      "76000000\n",
      "76500000\n",
      "77000000\n",
      "77500000\n",
      "78000000\n",
      "78500000\n",
      "79000000\n",
      "79500000\n",
      "80000000\n",
      "80500000\n",
      "81000000\n",
      "81500000\n",
      "82000000\n",
      "82500000\n",
      "83000000\n",
      "83500000\n",
      "84000000\n",
      "84500000\n",
      "85000000\n",
      "85500000\n",
      "86000000\n",
      "86500000\n",
      "87000000\n",
      "87500000\n",
      "--- 3607.0994210243225 seconds ---\n"
     ]
    }
   ],
   "source": [
    "-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-10-23 21:50:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "sdate = datetime.strptime(\"2016-10-23 21:50:00.000\", \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "\n",
    "print(sdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "p = re.compile('\\d+(\\.\\d+)?')\n",
    "strs = '---'\n",
    "\n",
    "cflot = (0.0 if p.match(strs) == None else float(strs))\n",
    "\n",
    "print (cflot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str = '0'\n",
    "\n",
    "float(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-37d709cd426a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n"
     ]
    }
   ],
   "source": [
    "if (10001 % 1000) == 0:\n",
    "    print('a')\n",
    "else :\n",
    "    print('b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "cnt = 1\n",
    "\n",
    "while cnt < 100:\n",
    "    if (cnt % 10) == 0:\n",
    "        print(cnt)\n",
    "    \n",
    "    cnt = cnt + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1477227000.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "at = datetime.strptime(\"2016-10-23 21:50:00.000\", \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "current_time = at.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "datetime.timestamp(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-09-21 09:00:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime \n",
    "\n",
    "print (datetime.fromtimestamp(1474416000))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Py35]",
   "language": "python",
   "name": "Python [Py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
